{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNKeLISZaAVUEWs1Vul6V+p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElijahWandimi/Datascience/blob/main/Image_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGyG0wFDgXWX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### downloading data"
      ],
      "metadata": {
        "id": "oHl1P1_NzKzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "G6CbMusvyof1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "E8pqZTqvyKqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sundarannamalai/hair-diseases"
      ],
      "metadata": {
        "id": "B8EoBA6Oxc-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir hair_diseases\n",
        "! unzip hair-diseases.zip -d hair_diseases\n"
      ],
      "metadata": {
        "id": "ve7LJJgTyc35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analysis\n",
        "grey scale conversion , HE , scalimg , shaping and feature extraction"
      ],
      "metadata": {
        "id": "NY2klSGMzPHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_root_path = '/content/hair_diseases/Hair Diseases - Final/train'\n",
        "\n",
        "class_paths = [os.path.join(train_root_path, f) for f in os.listdir(train_root_path)]\n",
        "\n",
        "train_imgs = []\n",
        "for cls in class_paths:\n",
        "  train_imgs += [os.path.join(cls, f) for f in os.listdir(cls)]"
      ],
      "metadata": {
        "id": "Gug3mw_ezGCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def display_image(img: torch.Tensor):\n",
        "  plt.imshow(img.permute(1, 2, 0).cpu())\n",
        "\n",
        "def convert_to_gray(img: torch.Tensor):\n",
        "  x = transforms.RandomGrayscale(p=0.8)\n",
        "  return x.forward(img)\n",
        "\n",
        "\n",
        "def HE_transform(img: torch.Tensor):\n",
        "  x = transforms.RandomEqualize(p=0.7)\n",
        "  return x.forward(img)\n",
        "\n",
        "def normalize_transform(img: torch.Tensor):\n",
        "  img = img.float()\n",
        "  x = transforms.Normalize(torch.mean(img), torch.std(img))\n",
        "  return x.forward(img)\n",
        "\n",
        "def scale_transform(img: torch.Tensor):\n",
        "  x = transforms.Resize((420, 420))\n",
        "  return x.forward(img)\n",
        "\n",
        "def transform_images(img: torch.Tensor):\n",
        "  return [HE_transform(img), convert_to_gray(img), normalize_transform(img), scale_transform(img)]\n"
      ],
      "metadata": {
        "id": "7pxjN74Q0p8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs[0]"
      ],
      "metadata": {
        "id": "jwOIh9zmNbQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = torchvision.io.read_image(train_imgs[0])\n",
        "tm_imgs = transform_images(example)\n",
        "\n",
        "titles = ['Histogram Equalization', 'Grayscale', 'Normalised {brightnes and hue}', 'Scaled {420 x 420}']\n",
        "\n",
        "fig, ax = plt.subplots(1, 4, figsize=(12, 10))\n",
        "for i in range(len(tm_imgs)):\n",
        "  ax[i].imshow(tm_imgs[i].permute(1, 2, 0).cpu())\n",
        "  ax[i].set_title(titles[i])"
      ],
      "metadata": {
        "id": "__XwcX5pAWUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomEqualize(p=0.7),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "dataset = ImageFolder(train_root_path, transform=transform)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "#  CNN Model\n",
        "class HairDiseaseCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(HairDiseaseCNN, self).__init__()\n",
        "        self.resnet = resnet18(pretrained=True)  # Load a pre-trained ResNet model\n",
        "        # Remove the last fully connected layer of ResNet\n",
        "        self.resnet = nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
        "        self.fc = nn.Linear(512, num_classes)    # Add a custom fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Step 3: Train the CNN\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_classes = len(dataset.classes)  # Number of classes in  hair disease dataset\n",
        "model = HairDiseaseCNN(num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "print(\"Training finished!\")\n",
        "\n",
        "# Step 4: Save the trained model if desired\n",
        "torch.save(model.state_dict(), \"hair_disease_cnn.pth\")"
      ],
      "metadata": {
        "id": "IA1Tz_Zfd93C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Create the dataset and DataLoader without RandomEqualize\n",
        "data_ext_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model_extractor = HairDiseaseCNN(num_classes).to(device)\n",
        "model_extractor.load_state_dict(torch.load(\"hair_disease_cnn.pth\"))\n",
        "\n",
        "model_extractor.eval()\n",
        "\n",
        "#  Feature Extraction\n",
        "all_features = []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in data_ext_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        features = model_extractor(inputs)\n",
        "        all_features.append(features)\n",
        "\n",
        "# Concatenate features from all batches into a single tensor\n",
        "features_tensor = torch.cat(all_features)\n",
        "\n",
        "# Now 'features_tensor' contains the extracted features from the model\n",
        "print(features_tensor.shape)"
      ],
      "metadata": {
        "id": "hNKECRDxAVAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_np = features_tensor.cpu().numpy()\n",
        "features_np = (features_np - features_np.mean(axis=0)) / features_np.std(axis=0)\n",
        "\n",
        "# Perform t-SNE on the features\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "embedded_features = tsne.fit_transform(features_np)\n",
        "\n",
        "class_labels = np.array([y for _, y in dataset])\n",
        "\n",
        "# Create a scatter plot for each class\n",
        "plt.figure(figsize=(10, 8))\n",
        "for class_idx in np.unique(class_labels):\n",
        "    class_mask = (class_labels == class_idx)\n",
        "    plt.scatter(embedded_features[class_mask, 0], embedded_features[class_mask, 1], label=f\"Class {class_idx}\", alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.legend()\n",
        "plt.title(\"t-SNE Visualization of Extracted Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x3X_1KAbvl79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvK-IX0GwnfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}